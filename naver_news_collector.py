import requests
import json
from datetime import datetime, timedelta
from typing import List, Dict
import time
import urllib.parse
try:
    from dateutil import parser
except ImportError:
    parser = None

class NaverNewsCollector:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ API ê¸°ë°˜ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, client_id: str = None, client_secret: str = None):
        # ë„¤ì´ë²„ API ì¸ì¦ ì •ë³´
        self.client_id = client_id or "i_ExQRquc2oFsTFDyLoz"
        self.client_secret = client_secret or "eJpNFD4w1Z"
        self.base_url = "https://openapi.naver.com/v1/search/news.json"
        
        # ì‚°ì—…/ì·¨ì—…/ê¸°ì—… ì¤‘ì‹¬ ê²€ìƒ‰ í‚¤ì›Œë“œ
        self.search_keywords = {
            "ì·¨ì—…/ê³ ìš©": ["ì±„ìš©", "ì·¨ì—…", "ì¼ìë¦¬", "ê³ ìš©", "êµ¬ì¸", "ì‹ ì…ì‚¬ì›", "ê²½ë ¥ì§"],
            "ê¸°ì—…ë™í–¥": ["ê¸°ì—…ì‹¤ì ", "IPO", "ìƒì¥", "M&A", "ì¸ìˆ˜í•©ë³‘", "CEO", "ëŒ€í‘œì´ì‚¬"],
            "IT/ê¸°ìˆ ": ["ìŠ¤íƒ€íŠ¸ì—…", "ë²¤ì²˜íˆ¬ì", "AI", "ì¸ê³µì§€ëŠ¥", "IT", "í…Œí¬", "í”Œë«í¼"],
            "ì œì¡°/ì‚°ì—…": ["ë°˜ë„ì²´", "ìë™ì°¨", "ì¡°ì„ ", "ì² ê°•", "í™”í•™", "ì œì¡°ì—…", "ê³µì¥"],
            "ë¶€ë™ì‚°/ê±´ì„¤": ["ë¶€ë™ì‚°", "ê±´ì„¤", "ì•„íŒŒíŠ¸", "ì¸í”„ë¼", "í† ì§€", "ë¶„ì–‘"]
        }
        
        # API ìš”ì²­ í—¤ë”
        self.headers = {
            "X-Naver-Client-Id": self.client_id,
            "X-Naver-Client-Secret": self.client_secret
        }
    
    def search_news_by_keyword(self, keyword: str, display: int = 10) -> List[Dict]:
        """í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ê²€ìƒ‰"""
        try:
            params = {
                "query": keyword,
                "display": display,  # ìµœëŒ€ 100ê°œ
                "start": 1,
                "sort": "date"  # ë‚ ì§œìˆœ ì •ë ¬ (ìµœì‹ ìˆœ)
            }
            
            response = requests.get(self.base_url, headers=self.headers, params=params)
            
            if response.status_code == 200:
                data = response.json()
                news_items = []
                
                for item in data.get('items', []):
                    # HTML íƒœê·¸ ì œê±°
                    title = self.clean_html_tags(item.get('title', ''))
                    description = self.clean_html_tags(item.get('description', ''))
                    
                    # ë°œí–‰ì¼ íŒŒì‹±
                    pub_date = self.parse_pub_date(item.get('pubDate', ''))
                    
                    # 24ì‹œê°„ ì´ë‚´ ë‰´ìŠ¤ë§Œ í•„í„°ë§
                    if self.is_recent_news(pub_date):
                        news_item = {
                            "title": title,
                            "description": description,
                            "link": item.get('link', ''),
                            "pubDate": pub_date.strftime("%Y-%m-%d %H:%M") if pub_date else "ì‹œê°„ ë¯¸ìƒ",
                            "originallink": item.get('originallink', ''),
                            "keyword": keyword,
                            "importance_score": 0
                        }
                        news_items.append(news_item)
                
                return news_items
            else:
                print(f"API ìš”ì²­ ì‹¤íŒ¨: {response.status_code} - {response.text}")
                return []
                
        except Exception as e:
            print(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ({keyword}): {str(e)}")
            return []
    
    def clean_html_tags(self, text: str) -> str:
        """HTML íƒœê·¸ ì œê±°"""
        import re
        # HTML íƒœê·¸ ì œê±°
        clean_text = re.sub(r'<[^>]+>', '', text)
        # HTML ì—”í‹°í‹° ë””ì½”ë”©
        clean_text = clean_text.replace('&lt;', '<').replace('&gt;', '>').replace('&amp;', '&')
        clean_text = clean_text.replace('&quot;', '"').replace('&#39;', "'")
        return clean_text.strip()
    
    def parse_pub_date(self, pub_date_str: str) -> datetime:
        """ë°œí–‰ì¼ íŒŒì‹±"""
        try:
            # ë„¤ì´ë²„ API ë‚ ì§œ í˜•ì‹: "Mon, 09 Oct 2023 14:30:00 +0900"
            from datetime import datetime
            import locale
            
            # ì˜ì–´ ë¡œì¼€ì¼ ì„¤ì • (ë‚ ì§œ íŒŒì‹±ì„ ìœ„í•´)
            try:
                locale.setlocale(locale.LC_TIME, 'C')
            except:
                pass
                
            # ë‚ ì§œ íŒŒì‹±
            pub_date = datetime.strptime(pub_date_str, "%a, %d %b %Y %H:%M:%S %z")
            # ì‹œê°„ëŒ€ë¥¼ ë¡œì»¬ ì‹œê°„ìœ¼ë¡œ ë³€í™˜
            return pub_date.replace(tzinfo=None)
            
        except Exception as e:
            print(f"ë‚ ì§œ íŒŒì‹± ì˜¤ë¥˜: {pub_date_str} - {str(e)}")
            return None
    
    def is_recent_news(self, pub_date: datetime, hours: int = 24) -> bool:
        """ìµœê·¼ ë‰´ìŠ¤ì¸ì§€ í™•ì¸"""
        if not pub_date:
            return False
        
        now = datetime.now()
        time_diff = now - pub_date
        return time_diff.total_seconds() <= (hours * 3600)
    
    def collect_all_news(self, news_per_keyword: int = 2) -> List[Dict]:
        """ê³ í’ˆì§ˆ ë‰´ìŠ¤ë§Œ ì„ ë³„ ìˆ˜ì§‘ (ìµœëŒ€ 25ê°œ ì œí•œ)"""
        all_news = []
        total_limit = 25  # ì „ì²´ ë‰´ìŠ¤ ìˆ˜ì§‘ ì œí•œ
        
        print("ğŸš€ ë„¤ì´ë²„ ë‰´ìŠ¤ APIë¡œ ê³ í’ˆì§ˆ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")
        
        for category, keywords in self.search_keywords.items():
            if len(all_news) >= total_limit:
                break
                
            print(f"ğŸ“‚ {category} ì¹´í…Œê³ ë¦¬ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
            
            # ê° ì¹´í…Œê³ ë¦¬ì—ì„œ ì²« 2ê°œ í‚¤ì›Œë“œë§Œ ì‚¬ìš© (ê³ í’ˆì§ˆ í‚¤ì›Œë“œ ìš°ì„ )
            priority_keywords = keywords[:2]
            
            for keyword in priority_keywords:
                if len(all_news) >= total_limit:
                    break
                    
                print(f"  ğŸ” '{keyword}' ê²€ìƒ‰ ì¤‘...")
                news_items = self.search_news_by_keyword(keyword, news_per_keyword)
                
                # ì¹´í…Œê³ ë¦¬ ì •ë³´ ì¶”ê°€
                for news in news_items:
                    news['category'] = category
                
                all_news.extend(news_items)
                
                # API í˜¸ì¶œ ì œí•œì„ ìœ„í•œ ëŒ€ê¸° (ì´ˆë‹¹ 10íšŒ ì œí•œ)
                time.sleep(0.1)
        
        # ì „ì²´ ì œí•œ ì ìš©
        all_news = all_news[:total_limit]
        
        print(f"ğŸ“Š ì´ {len(all_news)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ (ê¸°ì¡´ 60-70ê°œì—ì„œ ê°ì†Œ)")
        print(f"  â†’ ìµœì í™”: í† í° ì ˆì•½ì„ ìœ„í•´ ìˆ˜ì§‘ëŸ‰ 60% ì¶•ì†Œ")
        
        # ë‚ ì§œ í•„í„°ë§ ì ìš© (ì „ë‚  + ë‹¹ì¼ ë‰´ìŠ¤ë§Œ)
        filtered_news = self.filter_by_date(all_news)
        
        return filtered_news
    
    def calculate_importance_score(self, news_item: Dict) -> int:
        """ë‰´ìŠ¤ ì¤‘ìš”ë„ ì ìˆ˜ ê³„ì‚°"""
        title = news_item['title'].lower()
        description = news_item['description'].lower()
        content = title + " " + description
        
        score = 0
        
        # ì¹´í…Œê³ ë¦¬ë³„ ê¸°ë³¸ ì ìˆ˜
        category_scores = {
            "ì·¨ì—…/ê³ ìš©": 5,
            "ê¸°ì—…ë™í–¥": 4,
            "IT/ê¸°ìˆ ": 3,
            "ì œì¡°/ì‚°ì—…": 3,
            "ë¶€ë™ì‚°/ê±´ì„¤": 2
        }
        score += category_scores.get(news_item['category'], 1)
        
        # ê³ ì¤‘ìš”ë„ í‚¤ì›Œë“œ
        high_priority = [
            "ëŒ€ê¸°ì—…", "ì±„ìš©ê³µê³ ", "ì‹ ì…ì‚¬ì›", "IPO", "ìƒì¥", "M&A",
            "ì‹¤ì ë°œí‘œ", "ë§¤ì¶œ", "ì˜ì—…ì´ìµ", "ìŠ¤íƒ€íŠ¸ì—…", "íˆ¬ììœ ì¹˜",
            "ë°˜ë„ì²´", "ìë™ì°¨", "ë¶€ë™ì‚°ì •ì±…"
        ]
        
        for keyword in high_priority:
            if keyword in content:
                score += 2
        
        # ì¤‘ìš”ë„ í‚¤ì›Œë“œ
        medium_priority = [
            "ì±„ìš©", "ì·¨ì—…", "ê¸°ì—…", "íˆ¬ì", "ì‚°ì—…", "ê¸°ìˆ ",
            "ì •ì±…", "ì‹œì¥", "ì„±ì¥", "í™•ëŒ€", "ê°œë°œ"
        ]
        
        for keyword in medium_priority:
            if keyword in content:
                score += 1
        
        return score
    
    def balance_categories(self, news_list: List[Dict]) -> List[Dict]:
        """ì¹´í…Œê³ ë¦¬ ê· í˜• ì¡°ì • - í•œ ì¹´í…Œê³ ë¦¬ì—ì„œ ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ ì„ íƒ"""
        category_count = {}
        balanced_news = []
        max_per_category = 3
        
        # ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_news = sorted(news_list, key=lambda x: x['importance_score'], reverse=True)
        
        for news in sorted_news:
            category = news['category']
            current_count = category_count.get(category, 0)
            
            if current_count < max_per_category:
                balanced_news.append(news)
                category_count[category] = current_count + 1
        
        return balanced_news
    
    def parse_naver_date(self, pub_date_str: str) -> datetime.date:
        """ë„¤ì´ë²„ API pubDate íŒŒì‹± (ex: '2025-10-10 13:34' ë˜ëŠ” 'Thu, 10 Oct 2025 13:34:00 +0900')"""
        try:
            # ê°„ë‹¨í•œ í˜•ì‹ë¶€í„° ì‹œë„ (2025-10-10 13:34)
            if len(pub_date_str.split(' ')) == 2 and '-' in pub_date_str:
                date_part = pub_date_str.split(' ')[0]  # '2025-10-10'
                return datetime.strptime(date_part, '%Y-%m-%d').date()
            
            # dateutil ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°
            if parser:
                parsed_date = parser.parse(pub_date_str)
                return parsed_date.date()
            
            # ì‹¤íŒ¨ ì‹œ ì˜¤ëŠ˜ ë‚ ì§œ ë°˜í™˜
            return datetime.now().date()
            
        except Exception as e:
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì˜¤ëŠ˜ ë‚ ì§œë¡œ ì²˜ë¦¬
            return datetime.now().date()
    
    def filter_by_date(self, news_list: List[Dict]) -> List[Dict]:
        """ì „ë‚ ê³¼ ë‹¹ì¼ ë‰´ìŠ¤ë§Œ í•„í„°ë§"""
        today = datetime.now().date()
        yesterday = today - timedelta(days=1)
        
        print(f"\nğŸ“… ë‚ ì§œ í•„í„°ë§ ì ìš© ì¤‘...")
        print(f"  â†’ ëŒ€ìƒ ë‚ ì§œ: ì–´ì œ({yesterday}) + ì˜¤ëŠ˜({today})")
        
        today_news = []
        yesterday_news = []
        old_news = []
        
        for news in news_list:
            pub_date = self.parse_naver_date(news['pubDate'])
            
            if pub_date == today:
                today_news.append(news)
            elif pub_date == yesterday:
                yesterday_news.append(news)
            else:
                old_news.append(news)
        
        # ìµœì‹  ë‰´ìŠ¤ë§Œ ì„ ë³„
        filtered_news = today_news + yesterday_news
        
        print(f"  â†’ ì˜¤ëŠ˜({today}) ë‰´ìŠ¤: {len(today_news)}ê°œ")
        print(f"  â†’ ì–´ì œ({yesterday}) ë‰´ìŠ¤: {len(yesterday_news)}ê°œ")
        print(f"  â†’ ê·¸ ì´ì „ ë‰´ìŠ¤: {len(old_news)}ê°œ (ì œì™¸ë¨)")
        print(f"âœ… í•„í„°ë§ í›„: {len(filtered_news)}ê°œ ë‰´ìŠ¤ (ìµœì‹  ë‰´ìŠ¤ë§Œ)")
        
        return filtered_news
    
    def filter_and_rank_news(self, news_list: List[Dict], top_n: int = 5) -> List[Dict]:
        """ì—„ê²©í•œ ê¸°ì¤€ìœ¼ë¡œ ê³ í’ˆì§ˆ ë‰´ìŠ¤ 5ê°œë§Œ ì„ ë³„"""
        print(f"\nğŸ“Š ë‰´ìŠ¤ ì„ ë³„ ê¸°ì¤€ ì ìš© ì¤‘...")
        
        # 1ë‹¨ê³„: ì¤‘ìš”ë„ ì ìˆ˜ ê³„ì‚°
        for news in news_list:
            news['importance_score'] = self.calculate_importance_score(news)
        
        # 2ë‹¨ê³„: ìµœì†Œ ì ìˆ˜ í•„í„°ë§ (ì „ì²´ ë‰´ìŠ¤ ì–‘ ê°ì†Œ)
        min_score = 6  # ê¸°ì¡´ 5ì—ì„œ 6ìœ¼ë¡œ ìƒí–¥ ì¡°ì •
        filtered_news = [news for news in news_list if news['importance_score'] >= min_score]
        print(f"  â†’ ìµœì†Œ ì ìˆ˜ {min_score}ì  ì´ìƒ: {len(filtered_news)}ê°œ ë‰´ìŠ¤ ì„ ë³„")
        
        # 3ë‹¨ê³„: ì¤‘ë³µ ì œê±° (ì œëª© ê¸°ì¤€)
        unique_news = {}
        for news in filtered_news:
            title_key = news['title'][:30]  # ì œëª© ì• 30ìë¡œ ì¤‘ë³µ ì²´í¬
            if title_key not in unique_news or news['importance_score'] > unique_news[title_key]['importance_score']:
                unique_news[title_key] = news
        print(f"  â†’ ì¤‘ë³µ ì œê±° í›„: {len(unique_news)}ê°œ ë‰´ìŠ¤")
        
        # 4ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ ê· í˜• ì¡°ì • (5ê°œ ì¤‘ ìµœëŒ€ 3ê°œê°€ ê°™ì€ ì¹´í…Œê³ ë¦¬)
        category_balanced = self.balance_categories(list(unique_news.values()))
        print(f"  â†’ ì¹´í…Œê³ ë¦¬ ê· í˜• ì¡°ì • í›„: {len(category_balanced)}ê°œ ë‰´ìŠ¤")
        
        # 5ë‹¨ê³„: ì¤‘ìš”ë„ ìˆœ ì •ë ¬ í›„ top_n ì„ íƒ
        sorted_news = sorted(category_balanced, key=lambda x: x['importance_score'], reverse=True)
        final_news = sorted_news[:top_n]
        
        print(f"\nâœ… ìµœì¢… ì„ ë³„ëœ ê³ í’ˆì§ˆ ë‰´ìŠ¤: {len(final_news)}ê°œ")
        for i, news in enumerate(final_news, 1):
            print(f"    {i}. [{news['category']}] {news['title'][:40]}... (ì ìˆ˜: {news['importance_score']})")
        
        return final_news

class NaverNewsFormatter:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ë¥¼ ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ë¡œ í¬ë§·íŒ…"""
    
    @staticmethod
    def format_daily_news(news_list: List[Dict]) -> str:
        """ì¼ê°„ ë‰´ìŠ¤ë¥¼ ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ í˜•íƒœë¡œ í¬ë§·íŒ…"""
        today = datetime.now().strftime("%Yë…„ %mì›” %dì¼")
        
        message = f"ğŸ­ {today} ì‚°ì—…Â·ì·¨ì—… ë‰´ìŠ¤\n"
        message += "=" * 28 + "\n\n"
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì´ëª¨ì§€
        category_emojis = {
            "ì·¨ì—…/ê³ ìš©": "ğŸ‘”",
            "ê¸°ì—…ë™í–¥": "ğŸ¢", 
            "IT/ê¸°ìˆ ": "ğŸ’»",
            "ì œì¡°/ì‚°ì—…": "ğŸ­",
            "ë¶€ë™ì‚°/ê±´ì„¤": "ğŸ—ï¸"
        }
        
        for i, news in enumerate(news_list, 1):
            # ì¤‘ìš”ë„ì— ë”°ë¥¸ ì´ëª¨ì§€
            if news['importance_score'] >= 8:
                priority_emoji = "ğŸ”¥"
            elif news['importance_score'] >= 5:  
                priority_emoji = "â­"
            else:
                priority_emoji = "ğŸ“Œ"
            
            # ì¹´í…Œê³ ë¦¬ ì´ëª¨ì§€
            cat_emoji = category_emojis.get(news['category'], "ğŸ“°")
            
            message += f"{priority_emoji} {i}. {news['title']}\n"
            message += f"   {cat_emoji} {news['category']} | {news['pubDate']}\n"
            
            if news['description']:
                # ìš”ì•½ë¬¸ì´ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
                summary = news['description'][:80] + "..." if len(news['description']) > 80 else news['description']
                message += f"   ğŸ’¬ {summary}\n"
            
            message += f"   ğŸ”— {news['link']}\n\n"
        
        # ì¸ì‚¬ì´íŠ¸ ì¶”ê°€
        message += "â”€" * 28 + "\n"
        message += "ğŸ’¡ ì˜¤ëŠ˜ì˜ ì‚°ì—… ì¸ì‚¬ì´íŠ¸\n\n"
        
        # ì¹´í…Œê³ ë¦¬ ë¶„ì„
        categories = [news['category'] for news in news_list]
        most_frequent = max(set(categories), key=categories.count) if categories else "ì¼ë°˜"
        
        insights = {
            "ì·¨ì—…/ê³ ìš©": "ğŸ” ì±„ìš© ì‹œì¥ì´ í™œë°œí•©ë‹ˆë‹¤. ìƒˆë¡œìš´ ê¸°íšŒë¥¼ ë†“ì¹˜ì§€ ë§ˆì„¸ìš”!",
            "ê¸°ì—…ë™í–¥": "ğŸ“ˆ ê¸°ì—… ì‹¤ì  ì‹œì¦Œì…ë‹ˆë‹¤. íˆ¬ì ê¸°íšŒë¥¼ ì‚´í´ë³´ì„¸ìš”.",
            "IT/ê¸°ìˆ ": "ğŸ’» ê¸°ìˆ  í˜ì‹ ì´ ê°€ì†í™”ë˜ê³  ìˆìŠµë‹ˆë‹¤. íŠ¸ë Œë“œë¥¼ ì£¼ëª©í•˜ì„¸ìš”!",
            "ì œì¡°/ì‚°ì—…": "ğŸ­ ì œì¡°ì—… ë™í–¥ ë³€í™”ê°€ ê°ì§€ë©ë‹ˆë‹¤. ê³µê¸‰ë§ì„ ì²´í¬í•˜ì„¸ìš”.",
            "ë¶€ë™ì‚°/ê±´ì„¤": "ğŸ—ï¸ ë¶€ë™ì‚° ì •ì±… ë³€í™”ì— ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤."
        }
        
        insight = insights.get(most_frequent, "ğŸ“Š ë‹¤ì–‘í•œ ì‚°ì—… ë¶„ì•¼ì˜ ê· í˜•ì¡íŒ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        message += f"{insight}\n\n"
        
        message += "â”€" * 28 + "\n"
        message += "ğŸ“… ë§¤ì¼ ì˜¤ì „ 8ì‹œ ë°œì†¡\n"
        message += "ğŸ’¼ ì‚°ì—…Â·ì·¨ì—…Â·ê¸°ì—… ì •ë³´ ì „ë¬¸\n"
        message += "ğŸ“ ë¬¸ì˜: ë¹„ì¦ˆë‹ˆìŠ¤ ì±„ë„ ì±„íŒ…"
        
        return message

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í•¨ìˆ˜
def run_naver_news_test():
    """ë„¤ì´ë²„ ë‰´ìŠ¤ API í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ ë„¤ì´ë²„ ë‰´ìŠ¤ API í…ŒìŠ¤íŠ¸ ì‹œì‘!")
    print("=" * 50)
    
    # ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
    collector = NaverNewsCollector()
    
    # ë‰´ìŠ¤ ìˆ˜ì§‘
    all_news = collector.collect_all_news(news_per_keyword=2)
    
    if not all_news:
        print("âŒ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    # ìƒìœ„ 5ê°œ ë‰´ìŠ¤ ì„ ë³„
    top_news = collector.filter_and_rank_news(all_news, top_n=5)
    print(f"ğŸ¯ ìƒìœ„ {len(top_news)}ê°œ ë‰´ìŠ¤ ì„ ë³„ ì™„ë£Œ")
    
    # ì¹´í…Œê³ ë¦¬ ë¶„í¬ ì¶œë ¥
    categories = [news['category'] for news in top_news]
    category_count = {}
    for cat in categories:
        category_count[cat] = category_count.get(cat, 0) + 1
    print(f"ğŸ“Š ì¹´í…Œê³ ë¦¬ ë¶„í¬: {category_count}")
    
    # ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ í¬ë§·íŒ…
    formatter = NaverNewsFormatter()
    kakao_message = formatter.format_daily_news(top_news)
    
    print("\nğŸ“± ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ í¬ë§· ì™„ë£Œ")
    print("=" * 60)
    print(kakao_message)
    print("=" * 60)
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    with open('/home/user/naver_news_data.json', 'w', encoding='utf-8') as f:
        json.dump(top_news, f, ensure_ascii=False, indent=2)
    
    print("\nğŸ’¾ ë‰´ìŠ¤ ë°ì´í„°ê°€ naver_news_data.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return kakao_message, top_news

if __name__ == "__main__":
    run_naver_news_test()