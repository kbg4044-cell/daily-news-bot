"""
ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° - ì‚°ì—…ë³„ ë²„ì „
- 7ê°œ ì£¼ìš” ì‚°ì—…ë³„ ìˆ˜ì§‘
- 100+ ëŒ€ê¸°ì—… í‚¤ì›Œë“œ
- ì¤‘ìš”ë„ ì ìˆ˜ ê¸°ë°˜ ì„ ë³„
"""

import os
import requests
import re
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from html import unescape

class NaverNewsCollector:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ API ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        self.client_id = os.getenv('NAVER_CLIENT_ID')
        self.client_secret = os.getenv('NAVER_CLIENT_SECRET')
        self.base_url = "https://openapi.naver.com/v1/search/news.json"
        
        if not self.client_id or not self.client_secret:
            raise ValueError("âŒ ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        
        self.headers = {
            'X-Naver-Client-Id': self.client_id,
            'X-Naver-Client-Secret': self.client_secret
        }
        
        # ëŒ€ê¸°ì—… í‚¤ì›Œë“œ (100+ê°œ)
        self.major_companies = [
            # ì‚¼ì„±ê·¸ë£¹
            'ì‚¼ì„±ì „ì', 'ì‚¼ì„±ë””ìŠ¤í”Œë ˆì´', 'ì‚¼ì„±SDI', 'ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤', 'ì‚¼ì„±ë¬¼ì‚°',
            'ì‚¼ì„±ìƒëª…', 'ì‚¼ì„±í™”ì¬', 'ì‚¼ì„±ì¦ê¶Œ', 'ì‚¼ì„±ì¹´ë“œ', 'ì‚¼ì„±ì›°ìŠ¤í† ë¦¬',
            
            # SKê·¸ë£¹
            'SKí•˜ì´ë‹‰ìŠ¤', 'SKì´ë…¸ë² ì´ì…˜', 'SKí…”ë ˆì½¤', 'SKë¸Œë¡œë“œë°´ë“œ', 'SKC',
            'SKë„¤íŠ¸ì›ìŠ¤', 'SKì—ë„ˆì§€', 'SKì¼€ë¯¸ì¹¼', 'SKë°”ì´ì˜¤íŒœ', 'SKë°”ì´ì˜¤ì‚¬ì´ì–¸ìŠ¤',
            
            # í˜„ëŒ€ìë™ì°¨ê·¸ë£¹
            'í˜„ëŒ€ìë™ì°¨', 'ê¸°ì•„', 'í˜„ëŒ€ëª¨ë¹„ìŠ¤', 'í˜„ëŒ€ì œì² ', 'í˜„ëŒ€ê±´ì„¤',
            'í˜„ëŒ€ì—”ì§€ë‹ˆì–´ë§', 'í˜„ëŒ€ìœ„ì•„', 'í˜„ëŒ€ê¸€ë¡œë¹„ìŠ¤', 'í˜„ëŒ€ë¡œí…œ', 'í˜„ëŒ€ì˜¤í† ì—ë²„',
            
            # LGê·¸ë£¹
            'LGì „ì', 'LGí™”í•™', 'LGì—ë„ˆì§€ì†”ë£¨ì…˜', 'LGë””ìŠ¤í”Œë ˆì´', 'LGìœ í”ŒëŸ¬ìŠ¤',
            'LGìƒí™œê±´ê°•', 'LGí•˜ìš°ì‹œìŠ¤', 'LGì´ë…¸í…', 'LG CNS', 'LGí—¬ë¡œë¹„ì „',
            
            # ë¡¯ë°ê·¸ë£¹
            'ë¡¯ë°ì¼€ë¯¸ì¹¼', 'ë¡¯ë°ì‡¼í•‘', 'ë¡¯ë°ì¹ ì„±', 'ë¡¯ë°ì œê³¼', 'ë¡¯ë°í‘¸ë“œ',
            'ë¡¯ë°ì›°í‘¸ë“œ', 'ë¡¯ë°ê±´ì„¤', 'ë¡¯ë°ë Œíƒˆ', 'ë¡¯ë°ì •ë³´í†µì‹ ', 'í˜¸í…”ë¡¯ë°',
            
            # í¬ìŠ¤ì½”ê·¸ë£¹
            'í¬ìŠ¤ì½”', 'í¬ìŠ¤ì½”ì¸í„°ë‚´ì…”ë„', 'í¬ìŠ¤ì½”DX', 'í¬ìŠ¤ì½”ì¼€ë¯¸ì¹¼', 'í¬ìŠ¤ì½”ì—ë„ˆì§€',
            
            # í•œí™”ê·¸ë£¹
            'í•œí™”ì†”ë£¨ì…˜', 'í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤', 'í•œí™”ì˜¤ì…˜', 'í•œí™”ì‹œìŠ¤í…œ', 'í•œí™”ìƒëª…',
            'í•œí™”ì†í•´ë³´í—˜', 'í•œí™”íˆ¬ìì¦ê¶Œ', 'í•œí™”í˜¸í…”ì•¤ë“œë¦¬ì¡°íŠ¸',
            
            # ê¸ˆìœµê¶Œ
            'KBê¸ˆìœµ', 'ì‹ í•œê¸ˆìœµ', 'í•˜ë‚˜ê¸ˆìœµ', 'ìš°ë¦¬ê¸ˆìœµ', 'NHë†í˜‘',
            'ì¹´ì¹´ì˜¤ë±…í¬', 'í† ìŠ¤ë±…í¬', 'ì¼€ì´ë±…í¬', 'ë¯¸ë˜ì—ì…‹ì¦ê¶Œ', 'ì‚¼ì„±ì¦ê¶Œ',
            
            # í†µì‹ /IT
            'ë„¤ì´ë²„', 'ì¹´ì¹´ì˜¤', 'ì—”ì”¨ì†Œí”„íŠ¸', 'ë„·ë§ˆë¸”', 'í¬ë˜í”„í†¤',
            'ì¿ íŒ¡', 'ë°°ë‹¬ì˜ë¯¼ì¡±', 'ë‹¹ê·¼ë§ˆì¼“', 'í† ìŠ¤', 'ë¼ì¸',
            
            # ìœ í†µ/ì‹í’ˆ
            'ì‹ ì„¸ê³„', 'í˜„ëŒ€ë°±í™”ì ', 'GSë¦¬í…Œì¼', 'ì´ë§ˆíŠ¸', 'í™ˆí”ŒëŸ¬ìŠ¤',
            'ë†ì‹¬', 'CJì œì¼ì œë‹¹', 'ì˜¤ëšœê¸°', 'ì‚¼ì–‘ì‹í’ˆ', 'ë¹™ê·¸ë ˆ',
            'ë§¤ì¼ìœ ì—…', 'ë™ì›F&B', 'ëŒ€ìƒ', 'ì‚¬ì¡°',
            
            # ê±´ì„¤/ë¶€ë™ì‚°
            'GSê±´ì„¤', 'ëŒ€ìš°ê±´ì„¤', 'ëŒ€ë¦¼ì‚°ì—…', 'DLì´ì•¤ì”¨', 'HDCí˜„ëŒ€ì‚°ì—…ê°œë°œ',
            'ì¤‘í¥ê±´ì„¤', 'ì½”ì˜¤ë¡±ê¸€ë¡œë²Œ', 'íƒœì˜ê±´ì„¤',
            
            # í™”í•™/ì†Œì¬
            'í•œí™”ì†”ë£¨ì…˜', 'LGí™”í•™', 'ë¡¯ë°ì¼€ë¯¸ì¹¼', 'ê¸ˆí˜¸ì„ìœ í™”í•™', 'íš¨ì„±í™”í•™',
            'OCI', 'ì½”ì˜¤ë¡±ì¸ë”ìŠ¤íŠ¸ë¦¬', 'íœ´ë¹„ìŠ¤',
            
            # í•­ê³µ/ë¬¼ë¥˜
            'ëŒ€í•œí•­ê³µ', 'ì•„ì‹œì•„ë‚˜í•­ê³µ', 'ì§„ì—ì–´', 'í‹°ì›¨ì´í•­ê³µ', 'ì œì£¼í•­ê³µ',
            'CJëŒ€í•œí†µìš´', 'í•œì§„', 'í˜„ëŒ€ê¸€ë¡œë¹„ìŠ¤',
            
            # ì¡°ì„ 
            'í•œêµ­ì¡°ì„ í•´ì–‘', 'ì‚¼ì„±ì¤‘ê³µì—…', 'ëŒ€ìš°ì¡°ì„ í•´ì–‘', 'HDí˜„ëŒ€ì¤‘ê³µì—…', 'HDí•œêµ­ì¡°ì„ í•´ì–‘',
            
            # ë°”ì´ì˜¤/ì œì•½
            'ì…€íŠ¸ë¦¬ì˜¨', 'ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤', 'SKë°”ì´ì˜¤íŒœ', 'ìœ í•œì–‘í–‰', 'ë…¹ì‹­ì',
            'ëŒ€ì›…ì œì•½', 'í•œë¯¸ì•½í’ˆ', 'ì¢…ê·¼ë‹¹', 'ì¼ë™ì œì•½', 'ë™ì•„ì—ìŠ¤í‹°'
        ]
        
        # ì‚°ì—…ë³„ í‚¤ì›Œë“œ
        self.industry_keywords = {
            'ì¡°ì„ ': [
                'ì¡°ì„ ', 'ì„ ë°•', 'í•´ì–‘í”ŒëœíŠ¸', 'LNGì„ ', 'ì»¨í…Œì´ë„ˆì„ ',
                'ìˆ˜ì£¼', 'ë°œì£¼', 'ì¸ë„', 'ê±´ì¡°', 'í•œêµ­ì¡°ì„ í•´ì–‘', 'ì‚¼ì„±ì¤‘ê³µì—…',
                'ëŒ€ìš°ì¡°ì„ í•´ì–‘', 'HDí˜„ëŒ€ì¤‘ê³µì—…', 'HDí•œêµ­ì¡°ì„ í•´ì–‘'
            ],
            'ë°˜ë„ì²´': [
                'ë°˜ë„ì²´', 'ì¹©', 'ì›¨ì´í¼', 'Dë¨', 'ë‚¸ë“œ', 'NAND', 'SSD',
                'íŒŒìš´ë“œë¦¬', 'ì‚¼ì„±ì „ì', 'SKí•˜ì´ë‹‰ìŠ¤', 'ë©”ëª¨ë¦¬', 'ì‹œìŠ¤í…œë°˜ë„ì²´',
                'ë°˜ë„ì²´ì¥ë¹„', 'ë°˜ë„ì²´ì†Œì¬'
            ],
            'ì² ê°•': [
                'ì² ê°•', 'ê°•íŒ', 'ì—´ì—°', 'ëƒ‰ì—°', 'í›„íŒ', 'ìŠ¤í…Œì¸ë¦¬ìŠ¤',
                'í¬ìŠ¤ì½”', 'í˜„ëŒ€ì œì² ', 'ë™êµ­ì œê°•', 'ê³ ë¡œ', 'ì œì² ì†Œ'
            ],
            'ê¸ˆìœµ': [
                'ì€í–‰', 'ì¦ê¶Œ', 'ë³´í—˜', 'ìì‚°ìš´ìš©', 'ì¹´ë“œ', 'KBê¸ˆìœµ', 'ì‹ í•œê¸ˆìœµ',
                'í•˜ë‚˜ê¸ˆìœµ', 'ìš°ë¦¬ê¸ˆìœµ', 'ì¹´ì¹´ì˜¤ë±…í¬', 'í† ìŠ¤', 'IPO', 'ìƒì¥',
                'ëŒ€ì¶œ', 'ì˜ˆê¸ˆ', 'í€ë“œ'
            ],
            'ì‹í’ˆ': [
                'ì‹í’ˆ', 'ìŒë£Œ', 'ìœ í†µ', 'ë¼ë©´', 'ê³¼ì', 'ìŒë£Œìˆ˜',
                'ë†ì‹¬', 'CJì œì¼ì œë‹¹', 'ì˜¤ëšœê¸°', 'ë¡¯ë°ì œê³¼', 'ë¹™ê·¸ë ˆ',
                'ë§¤ì¼ìœ ì—…', 'ì‚¼ì–‘ì‹í’ˆ', 'ì‹ ì œí’ˆ', 'ì¶œì‹œ'
            ],
            'ê±´ì„¤': [
                'ê±´ì„¤', 'ì•„íŒŒíŠ¸', 'ë¶„ì–‘', 'ì¬ê°œë°œ', 'ì¬ê±´ì¶•', 'ì£¼íƒ',
                'í˜„ëŒ€ê±´ì„¤', 'GSê±´ì„¤', 'ëŒ€ìš°ê±´ì„¤', 'ëŒ€ë¦¼ì‚°ì—…', 'DLì´ì•¤ì”¨',
                'ìˆ˜ì£¼', 'ì°©ê³µ', 'ì…ì£¼'
            ],
            'ë°”ì´ì˜¤': [
                'ë°”ì´ì˜¤', 'ì œì•½', 'ì‹ ì•½', 'ì„ìƒ', 'ì˜ì•½í’ˆ', 'ë°±ì‹ ',
                'ì…€íŠ¸ë¦¬ì˜¨', 'ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤', 'SKë°”ì´ì˜¤íŒœ', 'ìœ í•œì–‘í–‰',
                'ìŠ¹ì¸', 'í—ˆê°€', 'ê°œë°œ', 'ê¸°ìˆ ì´ì „'
            ]
        }
        
        # ì‚°ì—…ë³„ ê³ ì¤‘ìš”ë„ í‚¤ì›Œë“œ
        self.industry_high_keywords = {
            'ì¡°ì„ ': ['ìˆ˜ì£¼', 'ë°œì£¼', 'ì¸ë„', 'ê³„ì•½', 'ì‹¤ì ', 'ë§¤ì¶œ', 'íˆ¬ì'],
            'ë°˜ë„ì²´': ['ìƒì‚°', 'íˆ¬ì', 'ê³µê¸‰', 'ìˆ˜ìš”', 'ê°€ê²©', 'ì‹¤ì ', 'ê°œë°œ', 'ê¸°ìˆ '],
            'ì² ê°•': ['ìƒì‚°', 'ê°€ê²©', 'ìˆ˜ì¶œ', 'íˆ¬ì', 'ì‹¤ì ', 'ì›ë£Œ', 'ìˆ˜ìš”'],
            'ê¸ˆìœµ': ['ì‹¤ì ', 'ëŒ€ì¶œ', 'ì˜ˆê¸ˆ', 'ìˆ˜ìµ', 'íˆ¬ì', 'ì¸ìˆ˜', 'í•©ë³‘', 'ìƒì¥'],
            'ì‹í’ˆ': ['ì¶œì‹œ', 'ë¡ ì¹­', 'ë§¤ì¶œ', 'ìˆ˜ì¶œ', 'ë¸Œëœë“œ', 'ì¸ìˆ˜', 'íˆ¬ì'],
            'ê±´ì„¤': ['ìˆ˜ì£¼', 'ë¶„ì–‘', 'ê°œë°œ', 'íˆ¬ì', 'ë§¤ì¶œ', 'í•´ì™¸', 'í”„ë¡œì íŠ¸'],
            'ë°”ì´ì˜¤': ['ìŠ¹ì¸', 'í—ˆê°€', 'ì„ìƒ', 'ê°œë°œ', 'íˆ¬ì', 'ìˆ˜ì¶œ', 'ê³„ì•½', 'ê¸°ìˆ ì´ì „']
        }
    
    def clean_html_tags(self, text: str) -> str:
        """HTML íƒœê·¸ ì œê±°"""
        text = re.sub(r'<[^>]+>', '', text)
        text = unescape(text)
        return text.strip()
    
    def parse_pub_date(self, pub_date: str) -> Optional[datetime]:
        """ë°œí–‰ì¼ íŒŒì‹±"""
        try:
            return datetime.strptime(pub_date, '%a, %d %b %Y %H:%M:%S %z')
        except:
            return None
    
    def is_recent_news(self, pub_date: str, hours: int = 48) -> bool:
        """ìµœê·¼ ë‰´ìŠ¤ ì—¬ë¶€ í™•ì¸"""
        parsed_date = self.parse_pub_date(pub_date)
        if not parsed_date:
            return True
        
        now = datetime.now(parsed_date.tzinfo)
        return (now - parsed_date).total_seconds() <= hours * 3600
    
    def search_news_by_keyword(self, keyword: str, display: int = 20) -> List[Dict]:
        """í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ê²€ìƒ‰"""
        params = {
            'query': keyword,
            'display': display,
            'sort': 'date'
        }
        
        try:
            response = requests.get(self.base_url, headers=self.headers, params=params)
            response.raise_for_status()
            data = response.json()
            
            news_list = []
            for item in data.get('items', []):
                if not self.is_recent_news(item.get('pubDate', '')):
                    continue
                
                news_list.append({
                    'title': self.clean_html_tags(item.get('title', '')),
                    'description': self.clean_html_tags(item.get('description', '')),
                    'link': item.get('link', ''),
                    'pub_date': item.get('pubDate', ''),
                    'keyword': keyword
                })
            
            return news_list
            
        except Exception as e:
            print(f"âš ï¸ ê²€ìƒ‰ ì‹¤íŒ¨ ({keyword}): {str(e)}")
            return []
    
    def calculate_industry_importance_score(self, news_item: Dict, industry: str) -> int:
        """ì‚°ì—…ë³„ ì¤‘ìš”ë„ ì ìˆ˜ ê³„ì‚°"""
        score = 5  # ê¸°ë³¸ ì ìˆ˜
        
        content = (news_item.get('title', '') + ' ' + news_item.get('description', '')).lower()
        
        # ì‚°ì—…ë³„ ê³ ì¤‘ìš”ë„ í‚¤ì›Œë“œ
        high_keywords = self.industry_high_keywords.get(industry, [])
        for keyword in high_keywords:
            if keyword.lower() in content:
                score += 3
        
        # ëŒ€ê¸°ì—… í‚¤ì›Œë“œ
        for company in self.major_companies:
            if company in content:
                score += 2
                break
        
        # ìˆ«ì í¬í•¨ (ì‹¤ì , ê¸ˆì•¡ ë“±)
        if re.search(r'\d+', content):
            score += 1
        
        # ì•¡ì…˜ í‚¤ì›Œë“œ
        action_keywords = ['ë°œí‘œ', 'ì¶œì‹œ', 'ê³„ì•½', 'íˆ¬ì', 'ì¸ìˆ˜', 'í•©ë³‘', 'ìŠ¹ì¸']
        for keyword in action_keywords:
            if keyword in content:
                score += 1
                break
        
        return score
    
    def select_top_news_for_industry(self, news_list: List[Dict], industry: str, top_n: int = 2) -> List[Dict]:
        """ì‚°ì—…ë³„ ìƒìœ„ ë‰´ìŠ¤ ì„ ë³„"""
        # ì ìˆ˜ ê³„ì‚°
        for news in news_list:
            news['importance_score'] = self.calculate_industry_importance_score(news, industry)
            news['industry'] = industry
        
        # ì¤‘ë³µ ì œê±° (ì œëª© ì• 40ì ê¸°ì¤€)
        unique_news = {}
        for news in news_list:
            title_key = news['title'][:40]
            if title_key not in unique_news or news['importance_score'] > unique_news[title_key]['importance_score']:
                unique_news[title_key] = news
        
        # ì ìˆ˜ ìˆœ ì •ë ¬
        sorted_news = sorted(unique_news.values(), key=lambda x: x['importance_score'], reverse=True)
        
        return sorted_news[:top_n]
    
    def collect_news_by_industry(self, news_per_industry: int = 2) -> List[Dict]:
        """
        ì‚°ì—…ë³„ ë‰´ìŠ¤ ìˆ˜ì§‘
        
        Args:
            news_per_industry: ì‚°ì—…ë‹¹ ìˆ˜ì§‘í•  ë‰´ìŠ¤ ê°œìˆ˜
        
        Returns:
            ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """
        all_news = []
        
        for industry, keywords in self.industry_keywords.items():
            print(f"\nğŸ” [{industry}] ìˆ˜ì§‘ ì¤‘...")
            industry_news = []
            
            # ê° í‚¤ì›Œë“œë¡œ ê²€ìƒ‰
            for keyword in keywords[:5]:  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œë§Œ
                news_list = self.search_news_by_keyword(keyword, display=10)
                industry_news.extend(news_list)
            
            if industry_news:
                # ìƒìœ„ ë‰´ìŠ¤ ì„ ë³„
                top_news = self.select_top_news_for_industry(industry_news, industry, news_per_industry)
                all_news.extend(top_news)
                print(f"   âœ… {len(top_news)}ê°œ ì„ ë³„ ì™„ë£Œ")
            else:
                print(f"   âš ï¸ ë‰´ìŠ¤ ì—†ìŒ")
        
        return all_news

class NaverNewsFormatter:
    """ë‰´ìŠ¤ í¬ë§·í„°"""
    
    @staticmethod
    def format_daily_news(news_list: List[Dict]) -> str:
        """ì¼ê°„ ë‰´ìŠ¤ í¬ë§·íŒ… (ì¹´ì¹´ì˜¤í†¡ìš©)"""
        # ì‚°ì—… ì´ëª¨ì§€
        industry_emoji = {
            'ì¡°ì„ ': 'ğŸš¢',
            'ë°˜ë„ì²´': 'ğŸ’¾',
            'ì² ê°•': 'ğŸ­',
            'ê¸ˆìœµ': 'ğŸ’°',
            'ì‹í’ˆ': 'ğŸœ',
            'ê±´ì„¤': 'ğŸ—ï¸',
            'ë°”ì´ì˜¤': 'ğŸ’Š'
        }
        
        today = datetime.now().strftime('%mì›” %dì¼')
        message = f"ğŸ“° ì‚°ì—…ë‰´ìŠ¤ ({today})\n"
        message += "â”" * 25 + "\n\n"
        
        for idx, news in enumerate(news_list[:10], 1):
            industry = news.get('industry', 'ê¸°íƒ€')
            emoji = industry_emoji.get(industry, 'ğŸ“Œ')
            title = news.get('title', 'ì œëª©ì—†ìŒ')
            
            if len(title) > 35:
                title = title[:32] + "..."
            
            message += f"{emoji} {title}\n"
        
        message += "\nâ”" * 25 + "\n"
        message += "â° ë§¤ì¼ ì˜¤ì „ 8ì‹œ ë°œì†¡\n"
        message += f"ğŸ“Š ì´ {len(news_list)}ê°œ ë‰´ìŠ¤"
        
        return message

def test_collector():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\n" + "="*70)
    print("ğŸ§ª ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° í…ŒìŠ¤íŠ¸")
    print("="*70)
    
    collector = NaverNewsCollector()
    news_list = collector.collect_news_by_industry(news_per_industry=2)
    
    print(f"\nğŸ“Š ì´ ìˆ˜ì§‘: {len(news_list)}ê°œ")
    
    # í¬ë§·íŒ…
    message = NaverNewsFormatter.format_daily_news(news_list)
    print("\n" + "="*70)
    print("ğŸ“ ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ ë¯¸ë¦¬ë³´ê¸°:")
    print("="*70)
    print(message)
    print(f"\në©”ì‹œì§€ ê¸¸ì´: {len(message)}ì")

if __name__ == "__main__":
    test_collector()
