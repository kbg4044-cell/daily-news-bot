import requests
import json
from datetime import datetime, timedelta
from typing import List, Dict
import time
import urllib.parse
try:
    from dateutil import parser
except ImportError:
    parser = None

class NaverNewsCollector:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ API ê¸°ë°˜ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, client_id: str = None, client_secret: str = None):
        # ë„¤ì´ë²„ API ì¸ì¦ ì •ë³´
        self.client_id = client_id or "i_ExQRquc2oFsTFDyLoz"
        self.client_secret = client_secret or "eJpNFD4w1Z"
        self.base_url = "https://openapi.naver.com/v1/search/news.json"
        
        # ëŒ€ê¸°ì—… í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        self.major_companies = [
            # ì‚¼ì„±ê·¸ë£¹
            "ì‚¼ì„±ì „ì", "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤", "ì‚¼ì„±SDI", "ì‚¼ì„±SDS", "ì‚¼ì„±ë¬¼ì‚°", "ì‚¼ì„±ìƒëª…", 
            "ì‚¼ì„±í™”ì¬", "ì‚¼ì„±ì¹´ë“œ", "ì‚¼ì„±ì¦ê¶Œ", "ì‚¼ì„±ì—”ì§€ë‹ˆì–´ë§", "ì‚¼ì„±ë””ìŠ¤í”Œë ˆì´", "ì‚¼ì„±ë°”ì´ì˜¤ì—í”¼ìŠ¤",
            
            # LGê·¸ë£¹
            "LGì „ì", "LGí™”í•™", "LGì—ë„ˆì§€ì†”ë£¨ì…˜", "LGë””ìŠ¤í”Œë ˆì´", "LGì´ë…¸í…", "LGìƒí™œê±´ê°•",
            "LGìœ í”ŒëŸ¬ìŠ¤", "LG CNS", "LGí•˜ìš°ì‹œìŠ¤", "LGí—¬ë¡œë¹„ì „",
            
            # SKê·¸ë£¹
            "SKí•˜ì´ë‹‰ìŠ¤", "SKí…”ë ˆì½¤", "SKì´ë…¸ë² ì´ì…˜", "SKë°”ì´ì˜¤íŒœ", "SKë°”ì´ì˜¤ì‚¬ì´ì–¸ìŠ¤",
            "SKì—ì½”í”ŒëœíŠ¸", "SKë„¤íŠ¸ì›ìŠ¤", "SKì¼€ë¯¸ì¹¼", "SKê°€ìŠ¤", "SKë¨¸í‹°ë¦¬ì–¼ì¦ˆ", "SKìŠ¤í€˜ì–´",
            
            # í˜„ëŒ€ìë™ì°¨ê·¸ë£¹
            "í˜„ëŒ€ìë™ì°¨", "ê¸°ì•„", "í˜„ëŒ€ëª¨ë¹„ìŠ¤", "í˜„ëŒ€ê¸€ë¡œë¹„ìŠ¤", "í˜„ëŒ€ê±´ì„¤", "í˜„ëŒ€ì œì² ",
            "í˜„ëŒ€ì—”ì§€ë‹ˆì–´ë§", "í˜„ëŒ€ì¼ë ‰íŠ¸ë¦­", "í˜„ëŒ€ë¡œí…œ", "í˜„ëŒ€ìœ„ì•„", "í˜„ëŒ€ì¤‘ê³µì—…", "í˜„ëŒ€ë¯¸í¬ì¡°ì„ ",
            
            # ë¡¯ë°ê·¸ë£¹
            "ë¡¯ë°ì¼€ë¯¸ì¹¼", "ë¡¯ë°ì‡¼í•‘", "ë¡¯ë°ì§€ì£¼", "ë¡¯ë°ì¹ ì„±ìŒë£Œ", "ë¡¯ë°ì›°í‘¸ë“œ", "ë¡¯ë°ì •ë°€í™”í•™",
            "ë¡¯ë°ë Œíƒˆ", "ë¡¯ë°ê´€ê´‘ê°œë°œ", "ë¡¯ë°í•˜ì´ë§ˆíŠ¸", "ë¡¯ë°í™€ë”©ìŠ¤", "ë¡¯ë°ì›”ë“œ", "ë¡¯ë°í‘¸ë“œ",
            
            # í¬ìŠ¤ì½”ê·¸ë£¹
            "í¬ìŠ¤ì½”í™€ë”©ìŠ¤", "í¬ìŠ¤ì½”", "í¬ìŠ¤ì½”ì¸í„°ë‚´ì…”ë„", "í¬ìŠ¤ì½”ì¼€ë¯¸ì¹¼", "í¬ìŠ¤ì½”DX",
            "í¬ìŠ¤ì½”ì´ì°¨ì „ì§€ì†Œì¬", "í¬ìŠ¤ì½”ì—ë„ˆì§€", "í¬ìŠ¤ì½”ê±´ì„¤", "í¬ìŠ¤ì½”í”Œëœí…",
            
            # í•œí™”ê·¸ë£¹
            "í•œí™”ì†”ë£¨ì…˜", "í•œí™”ì˜¤ì…˜", "í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤", "í•œí™”ì‹œìŠ¤í…œ", "í•œí™”ìƒëª…",
            "í•œí™”ì†í•´ë³´í—˜", "í•œí™”íˆ¬ìì¦ê¶Œ", "í•œí™”í˜¸í…”ì•¤ë“œë¦¬ì¡°íŠ¸", "í•œí™”íì…€", "í•œí™”ê°¤ëŸ¬ë¦¬ì•„",
            
            # ë‘ì‚°ê·¸ë£¹
            "ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹°", "ë‘ì‚°ë¡œë³´í‹±ìŠ¤", "ë‘ì‚°í“¨ì–¼ì…€", "ë‘ì‚°ê±´ì„¤", "ë‘ì‚°ë°¥ìº£", "ë‘ì‚°ì¤‘ê³µì—…",
            
            # GSê·¸ë£¹
            "GSê±´ì„¤", "GSë¦¬í…Œì¼", "GSì¹¼í…ìŠ¤", "GSí™ˆì‡¼í•‘", "GS25", "GS EPS",
            
            # ê¸ˆìœµì§€ì£¼/ì€í–‰
            "KBê¸ˆìœµì§€ì£¼", "ì‹ í•œì§€ì£¼", "í•˜ë‚˜ê¸ˆìœµì§€ì£¼", "ìš°ë¦¬ê¸ˆìœµì§€ì£¼", "NHë†í˜‘ê¸ˆìœµì§€ì£¼",
            "KBêµ­ë¯¼ì€í–‰", "ì‹ í•œì€í–‰", "í•˜ë‚˜ì€í–‰", "ìš°ë¦¬ì€í–‰", "NHë†í˜‘ì€í–‰", 
            "ì¹´ì¹´ì˜¤ë±…í¬", "í† ìŠ¤ë±…í¬", "ì¼€ì´ë±…í¬", "ë¯¸ë˜ì—ì…‹ì¦ê¶Œ", "NHíˆ¬ìì¦ê¶Œ",
            
            # ë³´í—˜
            "ì‚¼ì„±ìƒëª…", "í•œí™”ìƒëª…", "êµë³´ìƒëª…", "ë¯¸ë˜ì—ì…‹ìƒëª…", "ë™ì–‘ìƒëª…", "í¥êµ­ìƒëª…",
            "ì‚¼ì„±í™”ì¬", "í˜„ëŒ€í•´ìƒ", "DBì†í•´ë³´í—˜", "ë©”ë¦¬ì¸ í™”ì¬", "KBì†í•´ë³´í—˜",
            
            # IT/ê²Œì„/í”Œë«í¼
            "ë„¤ì´ë²„", "ì¹´ì¹´ì˜¤", "ì¹´ì¹´ì˜¤í˜ì´", "ì—”ì”¨ì†Œí”„íŠ¸", "ë„·ë§ˆë¸”", "í¬ë˜í”„í†¤", "NHN",
            "ìœ„ë©”ì´ë“œ", "í„ì–´ë¹„ìŠ¤", "ì»´íˆ¬ìŠ¤", "ë°ë¸Œì‹œìŠ¤í„°ì¦ˆ", "ì¹´ì¹´ì˜¤ê²Œì„ì¦ˆ", "ìŠ¤ë§ˆì¼ê²Œì´íŠ¸",
            "ë„¥ìŠ¨", "ì›¹ì  ", "ì— ê²Œì„", "í•œê²Œì„", "ë„¤ì˜¤ìœ„ì¦ˆ", "ì»´íˆ¬ìŠ¤í™€ë”©ìŠ¤",
            
            # í†µì‹ 
            "KT", "LGìœ í”ŒëŸ¬ìŠ¤", "SKí…”ë ˆì½¤", "SKë¸Œë¡œë“œë°´ë“œ", "KTìŠ¤ì¹´ì´ë¼ì´í”„",
            
            # í•­ê³µ/ë¬¼ë¥˜
            "ëŒ€í•œí•­ê³µ", "ì•„ì‹œì•„ë‚˜í•­ê³µ", "ì œì£¼í•­ê³µ", "ì§„ì—ì–´", "í‹°ì›¨ì´í•­ê³µ", "ì—ì–´ë¶€ì‚°",
            "CJëŒ€í•œí†µìš´", "í•œì§„", "í˜„ëŒ€ê¸€ë¡œë¹„ìŠ¤", "ë¡œì§€ìŠ¤ë°¸ë¦¬", "ì¿ íŒ¡", "ë§ˆì¼“ì»¬ë¦¬",
            
            # ìœ í†µ/ë°±í™”ì 
            "ì‹ ì„¸ê³„", "ë¡¯ë°ì‡¼í•‘", "ì´ë§ˆíŠ¸", "í™ˆí”ŒëŸ¬ìŠ¤", "ì½”ìŠ¤íŠ¸ì½”", "ë©”ê°€ë§ˆíŠ¸",
            "í˜„ëŒ€ë°±í™”ì ", "ê°¤ëŸ¬ë¦¬ì•„ë°±í™”ì ", "AKí”Œë¼ì", "NCë°±í™”ì ",
            
            # ì‹í’ˆ/ìƒí™œìš©í’ˆ
            "ë†ì‹¬", "ì˜¤ëšœê¸°", "CJì œì¼ì œë‹¹", "ë™ì›F&B", "ë¹™ê·¸ë ˆ", "ë§¤ì¼í™€ë”©ìŠ¤",
            "ë‚¨ì–‘ìœ ì—…", "í•œêµ­ì•¼ì¿ ë¥´íŠ¸", "ë¡¯ë°ì¹ ì„±ìŒë£Œ", "ì½”ì¹´ì½œë¼", "ì›…ì§„ì‹í’ˆ",
            "ì•„ëª¨ë ˆí¼ì‹œí”½", "LGìƒí™œê±´ê°•", "ì• ê²½ì‚°ì—…", "ìœ í•œí‚´ë²Œë¦¬", "í•œêµ­P&G",
            
            # ê±´ì„¤/ë¶€ë™ì‚°
            "í˜„ëŒ€ê±´ì„¤", "GSê±´ì„¤", "ëŒ€ë¦¼ì‚°ì—…", "ë‘ì‚°ê±´ì„¤", "íƒœì˜ê±´ì„¤", "HDCí˜„ëŒ€ì‚°ì—…ê°œë°œ",
            "í˜¸ë°˜ê±´ì„¤", "ëŒ€ìš°ê±´ì„¤", "ì¤‘í¥ê±´ì„¤", "ì½”ì˜¤ë¡±ê¸€ë¡œë²Œ", "í•œêµ­í† ì§€ì‹ íƒ",
            
            # í™”í•™/ì†Œì¬
            "LGí™”í•™", "í•œí™”ì†”ë£¨ì…˜", "SKì¼€ë¯¸ì¹¼", "ê¸ˆí˜¸ì„ìœ í™”í•™", "íš¨ì„±í™”í•™", "íš¨ì„±í‹°ì•¤ì”¨",
            "ì½”ì˜¤ë¡±ì¸ë”ìŠ¤íŠ¸ë¦¬", "íƒœê´‘ì‚°ì—…", "í›„ì„±", "OCI", "ë•ì–‘ì‚°ì—…", "SKì´ë…¸ë² ì´ì…˜",
            
            # ì² ê°•/ê¸ˆì†
            "í¬ìŠ¤ì½”", "í˜„ëŒ€ì œì² ", "ë™êµ­ì œê°•", "ë¶€êµ­ì² ê°•", "í•œêµ­ì² ê°•", "KGìŠ¤í‹¸",
            
            # ì¡°ì„ /í•´ìš´
            "í•œêµ­ì¡°ì„ í•´ì–‘", "ëŒ€ìš°ì¡°ì„ í•´ì–‘", "ì‚¼ì„±ì¤‘ê³µì—…", "í˜„ëŒ€ì¤‘ê³µì—…", "í•œì§„í•´ìš´", "HMM",
            
            # ì—ë„ˆì§€/ê³µê¸°ì—…
            "í•œêµ­ì „ë ¥", "í•œêµ­ê°€ìŠ¤ê³µì‚¬", "í•œêµ­ì„ìœ ê³µì‚¬", "í•œêµ­ìˆ˜ë ¥ì›ìë ¥", "í•œêµ­ì§€ì—­ë‚œë°©ê³µì‚¬",
            "SKê°€ìŠ¤", "GSì¹¼í…ìŠ¤", "S-Oil", "í˜„ëŒ€ì˜¤ì¼ë±…í¬",
            
            # ë°”ì´ì˜¤/ì œì•½
            "ì…€íŠ¸ë¦¬ì˜¨", "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤", "SKë°”ì´ì˜¤íŒœ", "í•œë¯¸ì•½í’ˆ", "ëŒ€ì›…ì œì•½", "ìœ í•œì–‘í–‰",
            "ë…¹ì‹­ì", "JWì¤‘ì™¸ì œì•½", "ì¢…ê·¼ë‹¹", "ë™ì•„ì—ìŠ¤í‹°", "ë¶€ê´‘ì•½í’ˆ", "í•œêµ­ì½œë§ˆ",
            
            # ë°˜ë„ì²´/ë””ìŠ¤í”Œë ˆì´
            "ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤", "LGë””ìŠ¤í”Œë ˆì´", "ì‚¼ì„±ë””ìŠ¤í”Œë ˆì´", "DBí•˜ì´í…", "ì‹¤ë¦¬ì½˜ì›ìŠ¤",
            
            # ê¸°íƒ€ ëŒ€ê¸°ì—…
            "KAI", "í•œêµ­í•­ê³µìš°ì£¼ì‚°ì—…", "ë‘ì‚°ë°¥ìº£", "ë³¼ë³´ê±´ì„¤ê¸°ê³„",
            "BGFë¦¬í…Œì¼", "GS25", "CU", "ì„¸ë¸ì¼ë ˆë¸", "ì´ë§ˆíŠ¸24", "ë¯¸ë‹ˆìŠ¤í†±"
        ]
        
        # ì‚°ì—…ë³„ í‚¤ì›Œë“œ (ê° ì‚°ì—…ë³„ë¡œ 2ê°œ ë‰´ìŠ¤ì”©)
        self.industry_keywords = {
            "ì¡°ì„ ": [
                # ì¡°ì„  ê¸°ì—…ë“¤
                "í˜„ëŒ€ì¤‘ê³µì—…", "ëŒ€ìš°ì¡°ì„ í•´ì–‘", "ì‚¼ì„±ì¤‘ê³µì—…", "í•œêµ­ì¡°ì„ í•´ì–‘", "í˜„ëŒ€ë¯¸í¬ì¡°ì„ ",
                # ì¡°ì„  ê´€ë ¨ í‚¤ì›Œë“œ
                "ì¡°ì„ ", "ì„ ë°•", "í•´ì–‘í”ŒëœíŠ¸", "LNGì„ ", "ì»¨í…Œì´ë„ˆì„ ", "í¬ë£¨ì¦ˆ", "ì¹œí™˜ê²½ì„ ë°•", 
                "ìŠ¤ë§ˆíŠ¸ì‹­", "í•´ìš´", "í•­ë§Œ", "ë¬¼ë¥˜ì„¼í„°", "ì„ ë°•ë°œì£¼", "ì¡°ì„ ì—…", "ì„ ë°•ìˆ˜ì£¼"
            ],
            "ë°˜ë„ì²´": [
                # ë°˜ë„ì²´ ê¸°ì—…ë“¤
                "ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤", "LGë””ìŠ¤í”Œë ˆì´", "ì‚¼ì„±ë””ìŠ¤í”Œë ˆì´", "DBí•˜ì´í…", 
                "ì‹¤ë¦¬ì½˜ì›ìŠ¤", "SKì‹¤íŠ¸ë¡ ", "ì†”ë¸Œë ˆì¸", "ë¨¸í‹°ë¦¬ì–¼ì¦ˆíŒŒí¬",
                # ë°˜ë„ì²´ ê´€ë ¨ í‚¤ì›Œë“œ
                "ë°˜ë„ì²´", "ë©”ëª¨ë¦¬", "ì‹œìŠ¤í…œë°˜ë„ì²´", "íŒŒìš´ë“œë¦¬", "ì›¨ì´í¼", "ì¹©", "Dë¨", "ë‚¸ë“œí”Œë˜ì‹œ",
                "GPU", "CPU", "AP", "ë°˜ë„ì²´ê³µê¸‰ë§", "ë°˜ë„ì²´íˆ¬ì", "ë°˜ë„ì²´ê³µì¥"
            ],
            "ì² ê°•": [
                # ì² ê°• ê¸°ì—…ë“¤
                "í¬ìŠ¤ì½”", "í˜„ëŒ€ì œì² ", "ë™êµ­ì œê°•", "ë¶€êµ­ì² ê°•", "í•œêµ­ì² ê°•", "KGìŠ¤í‹¸", "ì„¸ì•„ë² ìŠ¤í‹¸",
                # ì² ê°• ê´€ë ¨ í‚¤ì›Œë“œ
                "ì² ê°•", "ì œì² ", "ìŠ¤í…Œì¸ë¦¬ìŠ¤", "ì² ê´‘ì„", "ì½”í¬ìŠ¤", "ê³ ë¡œ", "ì „ê¸°ë¡œ", "ì••ì—°",
                "ì² ê°•ì¬", "ê°•ê´€", "ì„ ì¬", "ì² ìŠ¤í¬ë©", "ì² ê°•ìˆ˜ì¶œ", "ì² ê°•ê°€ê²©"
            ],
            "ê¸ˆìœµ": [
                # ê¸ˆìœµ ê¸°ì—…ë“¤
                "KBê¸ˆìœµì§€ì£¼", "ì‹ í•œì§€ì£¼", "í•˜ë‚˜ê¸ˆìœµì§€ì£¼", "ìš°ë¦¬ê¸ˆìœµì§€ì£¼", "NHë†í˜‘ê¸ˆìœµì§€ì£¼",
                "ì¹´ì¹´ì˜¤ë±…í¬", "í† ìŠ¤ë±…í¬", "ì¼€ì´ë±…í¬", "ë¯¸ë˜ì—ì…‹ì¦ê¶Œ", "NHíˆ¬ìì¦ê¶Œ", "KBì¦ê¶Œ",
                # ê¸ˆìœµ ê´€ë ¨ í‚¤ì›Œë“œ
                "ì€í–‰", "ì¦ê¶Œ", "ë³´í—˜", "ì¹´ë“œ", "ëŒ€ì¶œ", "ì˜ˆê¸ˆ", "ê¸ˆë¦¬", "í•€í…Œí¬", "ë””ì§€í„¸ë±…í‚¹",
                "ìì‚°ê´€ë¦¬", "íˆ¬ì", "IPO", "í€ë“œ", "ê¸ˆìœµì§€ì£¼", "ê¸ˆìœµì‹¤ì "
            ],
            "ì‹í’ˆ": [
                # ì‹í’ˆ ê¸°ì—…ë“¤
                "ë†ì‹¬", "ì˜¤ëšœê¸°", "CJì œì¼ì œë‹¹", "ë™ì›F&B", "ë¹™ê·¸ë ˆ", "ë§¤ì¼í™€ë”©ìŠ¤",
                "ë‚¨ì–‘ìœ ì—…", "í•œêµ­ì•¼ì¿ ë¥´íŠ¸", "ë¡¯ë°ì¹ ì„±ìŒë£Œ", "ì›…ì§„ì‹í’ˆ", "ì‚¼ì–‘ì‹í’ˆ",
                # ì‹í’ˆ ê´€ë ¨ í‚¤ì›Œë“œ
                "ì‹í’ˆ", "ìŒë£Œ", "ìœ ì œí’ˆ", "ë¼ë©´", "ê³¼ì", "ëƒ‰ë™ì‹í’ˆ", "ê±´ê°•ì‹í’ˆ", "í”„ëœì°¨ì´ì¦ˆ",
                "ì™¸ì‹", "ë°°ë‹¬", "ì‹ìì¬", "ì›ë£Œ", "ì‹í’ˆì•ˆì „", "ìˆ˜ì¶œ", "ë¸Œëœë“œ"
            ],
            "ê±´ì„¤": [
                # ê±´ì„¤ ê¸°ì—…ë“¤
                "í˜„ëŒ€ê±´ì„¤", "GSê±´ì„¤", "ëŒ€ë¦¼ì‚°ì—…", "ë‘ì‚°ê±´ì„¤", "íƒœì˜ê±´ì„¤", "HDCí˜„ëŒ€ì‚°ì—…ê°œë°œ",
                "í˜¸ë°˜ê±´ì„¤", "ëŒ€ìš°ê±´ì„¤", "ì¤‘í¥ê±´ì„¤", "ì½”ì˜¤ë¡±ê¸€ë¡œë²Œ", "í•œêµ­í† ì§€ì‹ íƒ",
                # ê±´ì„¤ ê´€ë ¨ í‚¤ì›Œë“œ
                "ê±´ì„¤", "ê±´ì¶•", "í† ëª©", "ì•„íŒŒíŠ¸", "ì˜¤í”¼ìŠ¤í…”", "ì¬ê°œë°œ", "ì¬ê±´ì¶•", "ë¶„ì–‘",
                "ì¸í”„ë¼", "ë„ë¡œ", "êµëŸ‰", "í„°ë„", "ê³µí•­", "í•­ë§Œ", "í”ŒëœíŠ¸", "í•´ì™¸ìˆ˜ì£¼"
            ],
            "ë°”ì´ì˜¤": [
                # ë°”ì´ì˜¤ ê¸°ì—…ë“¤
                "ì…€íŠ¸ë¦¬ì˜¨", "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤", "SKë°”ì´ì˜¤íŒœ", "í•œë¯¸ì•½í’ˆ", "ëŒ€ì›…ì œì•½", "ìœ í•œì–‘í–‰",
                "ë…¹ì‹­ì", "JWì¤‘ì™¸ì œì•½", "ì¢…ê·¼ë‹¹", "ë™ì•„ì—ìŠ¤í‹°", "ë¶€ê´‘ì•½í’ˆ", "í•œêµ­ì½œë§ˆ",
                # ë°”ì´ì˜¤ ê´€ë ¨ í‚¤ì›Œë“œ
                "ë°”ì´ì˜¤", "ì œì•½", "ì‹ ì•½", "ì˜ì•½í’ˆ", "ì„ìƒì‹œí—˜", "í—ˆê°€", "FDA", "ì‹ì•½ì²˜",
                "ë°”ì´ì˜¤ì‹œë°€ëŸ¬", "í•­ì²´", "ë°±ì‹ ", "ì¹˜ë£Œì œ", "ì˜ë£Œê¸°ê¸°", "í—¬ìŠ¤ì¼€ì–´", "ë””ì§€í„¸í—¬ìŠ¤"
            ]
        }
        
        # API ìš”ì²­ í—¤ë”
        self.headers = {
            "X-Naver-Client-Id": self.client_id,
            "X-Naver-Client-Secret": self.client_secret
        }
    
    def search_news_by_keyword(self, keyword: str, display: int = 10) -> List[Dict]:
        """í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ê²€ìƒ‰"""
        try:
            params = {
                "query": keyword,
                "display": display,
                "start": 1,
                "sort": "date"
            }
            
            response = requests.get(self.base_url, headers=self.headers, params=params)
            
            if response.status_code == 200:
                data = response.json()
                news_items = []
                
                for item in data.get('items', []):
                    title = self.clean_html_tags(item.get('title', ''))
                    description = self.clean_html_tags(item.get('description', ''))
                    pub_date = self.parse_pub_date(item.get('pubDate', ''))
                    
                    if self.is_recent_news(pub_date):
                        news_item = {
                            "title": title,
                            "description": description,
                            "link": item.get('link', ''),
                            "pubDate": pub_date.strftime("%Y-%m-%d %H:%M") if pub_date else "ì‹œê°„ ë¯¸ìƒ",
                            "originallink": item.get('originallink', ''),
                            "keyword": keyword,
                            "importance_score": 0
                        }
                        news_items.append(news_item)
                
                return news_items
            else:
                print(f"API ìš”ì²­ ì‹¤íŒ¨: {response.status_code} - {response.text}")
                return []
                
        except Exception as e:
            print(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ({keyword}): {str(e)}")
            return []
    
    def clean_html_tags(self, text: str) -> str:
        """HTML íƒœê·¸ ì œê±°"""
        import re
        clean_text = re.sub(r'<[^>]+>', '', text)
        clean_text = clean_text.replace('&lt;', '<').replace('&gt;', '>').replace('&amp;', '&')
        clean_text = clean_text.replace('&quot;', '"').replace('&#39;', "'")
        return clean_text.strip()
    
    def parse_pub_date(self, pub_date_str: str) -> datetime:
        """ë°œí–‰ì¼ íŒŒì‹±"""
        try:
            from datetime import datetime
            import locale
            
            try:
                locale.setlocale(locale.LC_TIME, 'C')
            except:
                pass
                
            pub_date = datetime.strptime(pub_date_str, "%a, %d %b %Y %H:%M:%S %z")
            return pub_date.replace(tzinfo=None)
            
        except Exception as e:
            print(f"ë‚ ì§œ íŒŒì‹± ì˜¤ë¥˜: {pub_date_str} - {str(e)}")
            return None
    
    def is_recent_news(self, pub_date: datetime, hours: int = 48) -> bool:
        """ìµœê·¼ ë‰´ìŠ¤ì¸ì§€ í™•ì¸ (48ì‹œê°„ìœ¼ë¡œ í™•ì¥)"""
        if not pub_date:
            return False
        
        now = datetime.now()
        time_diff = now - pub_date
        return time_diff.total_seconds() <= (hours * 3600)
    
    def collect_news_by_industry(self, news_per_industry: int = 2) -> List[Dict]:
        """ì‚°ì—…ë³„ë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘ (ê° ì‚°ì—…ë³„ 2ê°œì”©)"""
        all_news = []
        
        print("ğŸ­ ì‚°ì—…ë³„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")
        print(f"ğŸ“Š ëª©í‘œ: 7ê°œ ì‚°ì—… Ã— {news_per_industry}ê°œ = ì´ {7 * news_per_industry}ê°œ ë‰´ìŠ¤")
        
        for industry, keywords in self.industry_keywords.items():
            print(f"\nğŸ” {industry} ì‚°ì—… ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
            
            industry_news = []
            
            # ê° ì‚°ì—…ë³„ë¡œ ìƒìœ„ 5ê°œ í‚¤ì›Œë“œë§Œ ì‚¬ìš©
            priority_keywords = keywords[:5]
            
            for keyword in priority_keywords:
                if len(industry_news) >= news_per_industry * 3:  # ì—¬ìœ ë¶„ í™•ë³´
                    break
                    
                print(f"  ğŸ” '{keyword}' ê²€ìƒ‰ ì¤‘...")
                news_items = self.search_news_by_keyword(keyword, display=5)
                
                for news in news_items:
                    news['industry'] = industry
                    news['category'] = industry  # í˜¸í™˜ì„±ì„ ìœ„í•´
                
                industry_news.extend(news_items)
                time.sleep(0.1)  # API ì œí•œ ëŒ€ì‘
            
            # ê° ì‚°ì—…ë³„ë¡œ ìµœê³  í’ˆì§ˆ ë‰´ìŠ¤ë§Œ ì„ ë³„
            if industry_news:
                top_industry_news = self.select_top_news_for_industry(
                    industry_news, industry, news_per_industry
                )
                all_news.extend(top_industry_news)
                print(f"  âœ… {industry}: {len(top_industry_news)}ê°œ ë‰´ìŠ¤ ì„ ë³„")
            else:
                print(f"  âŒ {industry}: ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        
        print(f"\nğŸ¯ ì´ ìˆ˜ì§‘ëœ ë‰´ìŠ¤: {len(all_news)}ê°œ")
        return all_news
    
    def select_top_news_for_industry(self, news_list: List[Dict], industry: str, top_n: int) -> List[Dict]:
        """ê° ì‚°ì—…ë³„ë¡œ ìµœê³  í’ˆì§ˆ ë‰´ìŠ¤ ì„ ë³„"""
        if not news_list:
            return []
        
        # ì¤‘ìš”ë„ ì ìˆ˜ ê³„ì‚°
        for news in news_list:
            news['importance_score'] = self.calculate_industry_importance_score(news, industry)
        
        # ì¤‘ë³µ ì œê±° (ì œëª© ê¸°ì¤€)
        unique_news = {}
        for news in news_list:
            title_key = news['title'][:40]
            if title_key not in unique_news or news['importance_score'] > unique_news[title_key]['importance_score']:
                unique_news[title_key] = news
        
        # ì¤‘ìš”ë„ ìˆœ ì •ë ¬ í›„ ìƒìœ„ ì„ íƒ
        sorted_news = sorted(unique_news.values(), key=lambda x: x['importance_score'], reverse=True)
        return sorted_news[:top_n]
    
    def calculate_industry_importance_score(self, news_item: Dict, industry: str) -> int:
        """ì‚°ì—…ë³„ ë‰´ìŠ¤ ì¤‘ìš”ë„ ì ìˆ˜ ê³„ì‚° (ì„¸ë¶„í™”)"""
        title = news_item['title'].lower()
        description = news_item['description'].lower()
        content = title + " " + description
        
        score = 5  # ê¸°ë³¸ ì ìˆ˜
        
        # ì‚°ì—…ë³„ ê³ ì¤‘ìš”ë„ í‚¤ì›Œë“œ
        industry_high_keywords = {
            "ì¡°ì„ ": ["ìˆ˜ì£¼", "ë°œì£¼", "ì¸ë„", "ê³„ì•½", "ì‹¤ì ", "ë§¤ì¶œ", "íˆ¬ì"],
            "ë°˜ë„ì²´": ["ìƒì‚°", "íˆ¬ì", "ê³µê¸‰", "ìˆ˜ìš”", "ê°€ê²©", "ì‹¤ì ", "ê°œë°œ", "ê¸°ìˆ "],
            "ì² ê°•": ["ìƒì‚°", "ê°€ê²©", "ìˆ˜ì¶œ", "íˆ¬ì", "ì‹¤ì ", "ì›ë£Œ", "ìˆ˜ìš”"],
            "ê¸ˆìœµ": ["ì‹¤ì ", "ëŒ€ì¶œ", "ì˜ˆê¸ˆ", "ìˆ˜ìµ", "íˆ¬ì", "ì¸ìˆ˜", "í•©ë³‘", "ìƒì¥"],
            "ì‹í’ˆ": ["ì¶œì‹œ", "ë¡ ì¹­", "ë§¤ì¶œ", "ìˆ˜ì¶œ", "ë¸Œëœë“œ", "ì¸ìˆ˜", "íˆ¬ì"],
            "ê±´ì„¤": ["ìˆ˜ì£¼", "ë¶„ì–‘", "ê°œë°œ", "íˆ¬ì", "ë§¤ì¶œ", "í•´ì™¸", "í”„ë¡œì íŠ¸"],
            "ë°”ì´ì˜¤": ["ìŠ¹ì¸", "í—ˆê°€", "ì„ìƒ", "ê°œë°œ", "íˆ¬ì", "ìˆ˜ì¶œ", "ê³„ì•½", "ê¸°ìˆ ì´ì „"]
        }
        
        # ì‚°ì—…ë³„ ì¤‘ìš”ë„ í‚¤ì›Œë“œ ì ìˆ˜ ì¶”ê°€
        high_keywords = industry_high_keywords.get(industry, [])
        for keyword in high_keywords:
            if keyword in content:
                score += 3
        
        # ê¸°ì—…ëª… í¬í•¨ ì‹œ ì¶”ê°€ ì ìˆ˜
        for company in self.major_companies:
            if company.lower() in content:
                score += 2
                break
        
        # ìˆ«ì í¬í•¨ (ì‹¤ì , ê¸ˆì•¡ ë“±) ì‹œ ì¶”ê°€ ì ìˆ˜
        import re
        if re.search(r'\d+ì–µ|\d+ì¡°|\d+ë§Œ|\d+%', content):
            score += 2
        
        # ì¤‘ìš” ì•¡ì…˜ í‚¤ì›Œë“œ
        action_keywords = ["ë°œí‘œ", "ê³„íš", "ì¶”ì§„", "ë°œì£¼", "ìˆ˜ì£¼", "ì²´ê²°", "í•©ì˜", "ìŠ¹ì¸", "í—ˆê°€"]
        for keyword in action_keywords:
            if keyword in content:
                score += 1
        
        return score
    
    def get_balanced_news(self, news_list: List[Dict]) -> List[Dict]:
        """ì‚°ì—…ë³„ ê· í˜• ì¡°ì • (ê° ì‚°ì—… ìµœëŒ€ 2ê°œ)"""
        industry_count = {}
        balanced_news = []
        max_per_industry = 2
        
        # ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_news = sorted(news_list, key=lambda x: x['importance_score'], reverse=True)
        
        for news in sorted_news:
            industry = news.get('industry', news.get('category', 'ê¸°íƒ€'))
            current_count = industry_count.get(industry, 0)
            
            if current_count < max_per_industry:
                balanced_news.append(news)
                industry_count[industry] = current_count + 1
                
            # 14ê°œ ë‹¬ì„± ì‹œ ì¢…ë£Œ (7ê°œ ì‚°ì—… Ã— 2ê°œ)
            if len(balanced_news) >= 14:
                break
        
        return balanced_news
    
    def format_industry_distribution(self, news_list: List[Dict]) -> str:
        """ì‚°ì—…ë³„ ë¶„í¬ í˜„í™© ì¶œë ¥"""
        industry_count = {}
        for news in news_list:
            industry = news.get('industry', news.get('category', 'ê¸°íƒ€'))
            industry_count[industry] = industry_count.get(industry, 0) + 1
        
        result = "ğŸ“Š ì‚°ì—…ë³„ ë‰´ìŠ¤ ë¶„í¬:\n"
        for industry, count in industry_count.items():
            result += f"  â€¢ {industry}: {count}ê°œ\n"
        
        return result
    
    # í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ì¡´ ë©”ì†Œë“œëª… ìœ ì§€
    def collect_all_news(self, news_per_keyword: int = 2) -> List[Dict]:
        """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë©”ì†Œë“œ (collect_news_by_industry í˜¸ì¶œ)"""
        return self.collect_news_by_industry(news_per_industry=2)
    
    def filter_and_rank_news(self, news_list: List[Dict], top_n: int = 14) -> List[Dict]:
        """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë©”ì†Œë“œ (get_balanced_news í˜¸ì¶œ)"""
        return self.get_balanced_news(news_list)

class NaverNewsFormatter:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ë¥¼ ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ë¡œ í¬ë§·íŒ…"""
    
    @staticmethod
    def format_daily_news(news_list: List[Dict]) -> str:
        """ì¼ê°„ ë‰´ìŠ¤ë¥¼ ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ í˜•íƒœë¡œ í¬ë§·íŒ…"""
        today = datetime.now().strftime("%Yë…„ %mì›” %dì¼")
        
        message = f"ğŸ­ {today} ì£¼ìš” ì‚°ì—… ë‰´ìŠ¤\n"
        message += "=" * 30 + "\n\n"
        
        # ì‚°ì—…ë³„ ì´ëª¨ì§€
        industry_emojis = {
            "ì¡°ì„ ": "ğŸš¢",
            "ë°˜ë„ì²´": "ğŸ’»", 
            "ì² ê°•": "ğŸ­",
            "ê¸ˆìœµ": "ğŸ’°",
            "ì‹í’ˆ": "ğŸœ",
            "ê±´ì„¤": "ğŸ—ï¸",
            "ë°”ì´ì˜¤": "ğŸ§¬"
        }
        
        # ì‚°ì—…ë³„ë¡œ ê·¸ë£¹í™”
        industry_groups = {}
        for news in news_list:
            industry = news.get('industry', news.get('category', 'ê¸°íƒ€'))
            if industry not in industry_groups:
                industry_groups[industry] = []
            industry_groups[industry].append(news)
        
        # ì‚°ì—…ë³„ë¡œ ì¶œë ¥
        for industry, industry_news in industry_groups.items():
            emoji = industry_emojis.get(industry, "ğŸ“°")
            message += f"{emoji} {industry} ì‚°ì—…\n"
            message += "â”€" * 20 + "\n"
            
            for i, news in enumerate(industry_news, 1):
                # ì¤‘ìš”ë„ í‘œì‹œ
                if news['importance_score'] >= 12:
                    priority = "ğŸ”¥ HOT"
                elif news['importance_score'] >= 9:
                    priority = "â­ ì£¼ëª©"
                else:
                    priority = "ğŸ“Œ ì¼ë°˜"
                
                message += f"{priority} {news['title']}\n"
                
                if news['description']:
                    summary = news['description'][:60] + "..." if len(news['description']) > 60 else news['description']
                    message += f"ğŸ’¬ {summary}\n"
                
                message += f"ğŸ• {news['pubDate']}\n"
                message += f"ğŸ”— {news['link']}\n\n"
            
            message += "\n"
        
        # ì¸ì‚¬ì´íŠ¸ ì¶”ê°€
        message += "ğŸ’¡ ì˜¤ëŠ˜ì˜ ì‚°ì—… ì¸ì‚¬ì´íŠ¸\n"
        message += "â”€" * 25 + "\n"
        
        # ê°€ì¥ ë§ì€ ë‰´ìŠ¤ê°€ ë‚˜ì˜¨ ì‚°ì—… ë¶„ì„
        industry_counts = {}
        for news in news_list:
            industry = news.get('industry', news.get('category', 'ê¸°íƒ€'))
            industry_counts[industry] = industry_counts.get(industry, 0) + 1
        
        if industry_counts:
            most_active = max(industry_counts.items(), key=lambda x: x[1])
            insights = {
                "ì¡°ì„ ": "ğŸš¢ ì¡°ì„ ì—…ê³„ ë™í–¥ì´ í™œë°œí•©ë‹ˆë‹¤. ìˆ˜ì£¼ ì‹¤ì ì„ ì£¼ëª©í•˜ì„¸ìš”!",
                "ë°˜ë„ì²´": "ğŸ’» ë°˜ë„ì²´ ì‹œì¥ ë³€í™”ê°€ ê°ì§€ë©ë‹ˆë‹¤. ê³µê¸‰ë§ì„ ì²´í¬í•˜ì„¸ìš”!",
                "ì² ê°•": "ğŸ­ ì² ê°•ì—…ê³„ íë¦„ ë³€í™”ì— ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
                "ê¸ˆìœµ": "ğŸ’° ê¸ˆìœµì‹œì¥ ë™í–¥ì„ ë©´ë°€íˆ ì‚´í´ë³´ì„¸ìš”.",
                "ì‹í’ˆ": "ğŸœ ì‹í’ˆì—…ê³„ ìƒˆë¡œìš´ íŠ¸ë Œë“œê°€ ë‚˜íƒ€ë‚˜ê³  ìˆìŠµë‹ˆë‹¤.",
                "ê±´ì„¤": "ğŸ—ï¸ ê±´ì„¤ì—…ê³„ ìˆ˜ì£¼ ë™í–¥ì„ í™•ì¸í•˜ì„¸ìš”.",
                "ë°”ì´ì˜¤": "ğŸ§¬ ë°”ì´ì˜¤ ë¶„ì•¼ ê¸°ìˆ  ë°œì „ì´ ê°€ì†í™”ë˜ê³  ìˆìŠµë‹ˆë‹¤."
            }
            
            insight = insights.get(most_active[0], "ğŸ“Š ë‹¤ì–‘í•œ ì‚°ì—… ë¶„ì•¼ì˜ ê· í˜•ì¡íŒ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            message += f"{insight}\n\n"
        
        message += "â”€" * 30 + "\n"
        message += "ğŸ“… ë§¤ì¼ ì˜¤ì „ 8ì‹œ ë°œì†¡\n"
        message += "ğŸ­ 7ëŒ€ ì£¼ìš” ì‚°ì—… ì „ë¬¸ ì •ë³´\n" 
        message += "ğŸ“ ë¬¸ì˜: ë¹„ì¦ˆë‹ˆìŠ¤ ì±„ë„ ì±„íŒ…"
        
        return message

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í•¨ìˆ˜
def run_naver_news_test():
    """ë„¤ì´ë²„ ë‰´ìŠ¤ API í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ ì‚°ì—…ë³„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘!")
    print("=" * 60)
    
    # ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
    collector = NaverNewsCollector()
    
    # ì‚°ì—…ë³„ ë‰´ìŠ¤ ìˆ˜ì§‘ (ê° ì‚°ì—…ë³„ 2ê°œì”©)
    all_news = collector.collect_news_by_industry(news_per_industry=2)
    
    if not all_news:
        print("âŒ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    # ì‚°ì—…ë³„ ê· í˜• ì¡°ì •
    balanced_news = collector.get_balanced_news(all_news)
    print(f"\nğŸ¯ ìµœì¢… ì„ ë³„ëœ ë‰´ìŠ¤: {len(balanced_news)}ê°œ")
    
    # ì‚°ì—…ë³„ ë¶„í¬ ì¶œë ¥
    print(collector.format_industry_distribution(balanced_news))
    
    # ë‰´ìŠ¤ í’ˆì§ˆ ë¶„ì„
    high_quality = [n for n in balanced_news if n['importance_score'] >= 10]
    medium_quality = [n for n in balanced_news if 7 <= n['importance_score'] < 10]
    normal_quality = [n for n in balanced_news if n['importance_score'] < 7]
    
    print(f"ğŸ“ˆ ë‰´ìŠ¤ í’ˆì§ˆ ë¶„ì„:")
    print(f"  ğŸ”¥ ê³ í’ˆì§ˆ (10ì  ì´ìƒ): {len(high_quality)}ê°œ")
    print(f"  â­ ì¤‘í’ˆì§ˆ (7-9ì ): {len(medium_quality)}ê°œ") 
    print(f"  ğŸ“Œ ì¼ë°˜ (7ì  ë¯¸ë§Œ): {len(normal_quality)}ê°œ")
    
    # ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ í¬ë§·íŒ…
    formatter = NaverNewsFormatter()
    kakao_message = formatter.format_daily_news(balanced_news)
    
    print("\nğŸ“± ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ í¬ë§· ì™„ë£Œ")
    print("=" * 80)
    print(kakao_message)
    print("=" * 80)
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    with open('/home/user/industry_news_data.json', 'w', encoding='utf-8') as f:
        json.dump(balanced_news, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ë‰´ìŠ¤ ë°ì´í„°ê°€ industry_news_data.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ“Š ë©”ì‹œì§€ ê¸¸ì´: {len(kakao_message)}ì (ì¹´ì¹´ì˜¤í†¡ ì œí•œ: 1000ì)")
    
    return kakao_message, balanced_news

if __name__ == "__main__":
    run_naver_news_test()
